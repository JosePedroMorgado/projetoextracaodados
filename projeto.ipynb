{"cells":[{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pandas in c:\\users\\josé pedro morgado\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n","Requirement already satisfied: pyarrow in c:\\users\\josé pedro morgado\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (17.0.0)\n","Collecting sqlalchemy\n","  Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n","Collecting psycopg2\n","  Downloading psycopg2-2.9.10-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n","Requirement already satisfied: numpy>=1.26.0 in c:\\users\\josé pedro morgado\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\josé pedro morgado\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\josé pedro morgado\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\josé pedro morgado\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2023.3)\n","Collecting typing-extensions>=4.6.0 (from sqlalchemy)\n","  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n","Collecting greenlet!=0.4.17 (from sqlalchemy)\n","  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n","Requirement already satisfied: six>=1.5 in c:\\users\\josé pedro morgado\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Downloading SQLAlchemy-2.0.36-cp312-cp312-win_amd64.whl (2.1 MB)\n","   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n","   ------------------------- -------------- 1.3/2.1 MB 11.2 MB/s eta 0:00:01\n","   ---------------------------------------- 2.1/2.1 MB 11.7 MB/s eta 0:00:00\n","Downloading psycopg2-2.9.10-cp312-cp312-win_amd64.whl (1.2 MB)\n","   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n","   ---------------------------------------- 1.2/1.2 MB 11.6 MB/s eta 0:00:00\n","Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n","Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n","Installing collected packages: typing-extensions, psycopg2, greenlet, sqlalchemy\n","Successfully installed greenlet-3.1.1 psycopg2-2.9.10 sqlalchemy-2.0.36 typing-extensions-4.12.2\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install pandas pyarrow sqlalchemy psycopg2"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Colunas disponíveis no CSV: Index(['Unnamed: 0', 'price', 'brand', 'model', 'year', 'title_status',\n","       'mileage', 'color', 'vin', 'lot', 'state', 'country', 'condition'],\n","      dtype='object')\n","\n","Resultado final após as transformações:\n","\n","      price      brand    model  year  car_age   mileage       state country\n","0      6300     toyota  cruiser  2008       16  274117.0  new jersey     usa\n","2      5350      dodge      mpv  2018        6   39590.0     georgia     usa\n","3     25000       ford     door  2014       10   64146.0    virginia     usa\n","4     27700  chevrolet     1500  2018        6    6654.0     florida     usa\n","5      5700      dodge      mpv  2018        6   45561.0       texas     usa\n","...     ...        ...      ...   ...      ...       ...         ...     ...\n","2494   7800     nissan    versa  2019        5   23609.0  california     usa\n","2495   9200     nissan    versa  2018        6   34553.0     florida     usa\n","2496   9200     nissan    versa  2018        6   31594.0     florida     usa\n","2497   9200     nissan    versa  2018        6   32557.0     florida     usa\n","2498   9200     nissan    versa  2018        6   31371.0     florida     usa\n","\n","[2188 rows x 8 columns]\n"]}],"source":["import pandas as pd\n","\n","# Função para a extração de dados de um arquivo CSV\n","def extract_from_csv(file_path):\n","    return pd.read_csv(file_path)\n","\n","# Função para transformar dados (limpeza, padronização, etc)\n","def transform_data(df):\n","    # Exibir as colunas do DataFrame\n","    print(\"Colunas disponíveis no CSV:\", df.columns)\n","\n","    # Exemplo de limpeza: Remover valores nulos\n","    df = df.dropna()\n","\n","    # Filtrar carros com preço acima de $5000\n","    if 'price' in df.columns:\n","        df = df[df['price'] > 5000]  # Filtrando linhas com valor 'price' > 5000\n","    else:\n","        print(\"Coluna 'price' não encontrada. Verifique o nome da coluna no CSV.\")\n","\n","    # Enriquecimento: criar uma nova coluna 'car_age' com a idade do carro\n","    current_year = pd.Timestamp.now().year\n","    if 'year' in df.columns:\n","        df['car_age'] = current_year - df['year']\n","    else:\n","        print(\"Coluna 'year' não encontrada. Verifique o nome da coluna no CSV.\")\n","\n","    # Selecionar apenas colunas relevantes\n","    df = df[['price', 'brand', 'model', 'year', 'car_age', 'mileage', 'state', 'country']]\n","\n","    return df\n","\n","# Função para exibir o DataFrame em formato de tabela\n","def display_table(df):\n","    # Configurar pandas para mostrar todas as colunas e até 20 linhas\n","    pd.set_option('display.max_columns', None)  # Mostra todas as colunas\n","    pd.set_option('display.max_rows', 20)       # Limita a exibição a 20 linhas\n","\n","    print(\"\\nResultado final após as transformações:\\n\")\n","    print(df)\n","\n","# Função para salvar dados no formato Parquet\n","def load_to_parquet(df, output_file):\n","    df.to_parquet(output_file, engine='pyarrow')\n","\n","# Função principal do pipeline ETL\n","def etl_pipeline(csv_file, parquet_output):\n","    # Extração de dados do arquivo CSV\n","    csv_data = extract_from_csv(csv_file)\n","\n","    # Transformação dos dados\n","    transformed_data = transform_data(csv_data)\n","\n","    # Exibir os dados transformados em formato de tabela\n","    display_table(transformed_data)\n","\n","    # Carga dos dados transformados em Parquet\n","    load_to_parquet(transformed_data, parquet_output)\n","\n","if __name__ == \"__main__\":\n","    # Definir o caminho do arquivo CSV e o local de saída do Parquet\n","    csv_file_path = 'C:/Users/José Pedro Morgado/Desktop/projeto/USA_cars_datasets.csv'\n","    parquet_output_path = 'C:/Users/José Pedro Morgado/Desktop/projeto/dados_final.parquet'\n","\n","    # Executar o pipeline ETL\n","    etl_pipeline(csv_file_path, parquet_output_path)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":2}
